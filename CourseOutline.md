# Generative Deep Learning in Python

## Chapter 1: Generative deep learning for text

### Lesson 1.1: Introducing generative deep learning

  * Learner will be able to name some of the recent applications of generative deep learning.
  * Learner will be able to understand the potential of generative deep learning.

### Lesson 1.2: Reweighting probability distributions with the softmax temperature

  * Learner will be able to distinguish between greedy and stochastic sampling.
  * Learner will be able to create a function that reweights a given probability distribution to control the degree of stochasticity.

### Lesson 1.3: Parsing the *philosopher* dataset

  * Learner will be able to understand the *philosopher* dataset, which contains many texts from {choose your favorite philosopher}.
  * Learner will be able to use keras.utils.get_file to load the dataset from the web.

### Lesson 1.4: Vectorizing sequences of characters

  * Learner will be able to prepare the training and target data to be used later in a later model.fit; this is achieved extracting partially overlapping sequences from the *philosopher* dataset, together with the characters that come after each sequence. 

## Chapter 2: Implementing a text generator with Keras

### Lesson 2.1: Creating a Long Short Term Memory neural network for character prediction

  * Learner will be able to create a neural network suited for character prediction; this is achieved compiling a neuran network with a Long Short Term Memory layer.

### Lesson 2.2: A sampling function based on model's predictions

  * Learner will be able to create a function that generates new characters based on the model's prediction and a given softmax temperature.

### Lesson 2.3: The artificial text generation loop

  * Learner will be able to create a loop of the previous function that generates a full text, inspired in the philosopher's style.

### Lesson 2.4: The effect of temperature on the generated text

  * Learner will be able to experiment with the effects of the softmax temperature in the artificial text.
  * Learner will be able to judge the potential of deep learning for text generation.

## Chapter 3: Generative deep learning for images

### Lesson 3.1: Visual art with generative deep learning 

  * Learner will be able to

### Lesson 3.2: DeepDream's Inception model

  * Learner will be able to

### Lesson 3.3: Defining the loss to be maximized

  * Learner will be able to

### Lesson 3.4: The gradient-ascent process

  * Learner will be able to

## Chapter 4: Implementing DeepDream with Keras

### Lesson 4.1: Some auxiliary functions

  * Learner will be able to

### Lesson 4.2: Looping over scales

  * Learner will be able to

### Lesson 4.3: The effect of the size ratio between scales

  * Learner will be able to

### Lesson 4.4: The future of generative deep learning

  * Learner will be able to

# Notes

This outline is mainly based on:

  * Fran√ßois Chollet, "Chapter 8: Generative Deep Learning," in *Deep Learning with Python*, Manning Publications, 2018.
  
In reality, as project manager, I would work with the legal team and the course instructor to ensure that there are no copyright issues with the code and datasets employed.
