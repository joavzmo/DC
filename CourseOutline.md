# Generative Deep Learning in Python

## Chapter 1: Generative deep learning for text

### Lesson 1.1: Introducing generative deep learning

  * Learning objective: 

### Lesson 1.2: Reweighting probability distributions with the softmax temperature

  * Learning objective: 

### Lesson 1.3: Parsing the Nietzsche dataset

  * Learning objective: 

### Lesson 1.4: Vectorizing sequences of characters

  * Learning objective: 

## Chapter 2: Implementing a text generator with Keras

### Lesson 2.1: Creating a Long Short Term Memory neural network for character prediction

  * Learning objective: 

### Lesson 2.2: A sampling function based on model's predictions

  * Learning objective: 

### Lesson 2.3: The artificial text generation loop

  * Learning objective: 

### Lesson 2.4: The effect of temperature on the generated text

  * Learning objective: 

## Chapter 3: Generative deep learning for images

### Lesson 3.1: Visual art with generative deep learning 

  * Learning objective: 

### Lesson 3.2: DeepDream's Inception model

  * Learning objective: 

### Lesson 3.3: Defining the loss to be maximized

  * Learning objective: 

### Lesson 3.4: The gradient-ascent process

  * Learning objective: 

## Chapter 4: Implementing DeepDream with Keras

### Lesson 4.1: Some auxiliary functions

  * Learning objective: 

### Lesson 4.2: Looping over scales

  * Learning objective: 

### Lesson 4.3: The effect of the size ratio between scales

  * Learning objective: 

### Lesson 4.4: The future of generative deep learning

  * Learning objective: 

# Notes

This outline is mainly based on:

  * Fran√ßois Chollet, "Chapter 8: Generative Deep Learning," in *Deep Learning with Python*, Manning Publications, 2018.
  
In reality, as project manager, I would work with the legal team and the course instructor to ensure that there are no copyright issues with the code and datasets employed.
